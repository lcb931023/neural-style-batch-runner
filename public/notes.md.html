<!DOCTYPE html>
<html>
  <head>
      <meta charset="utf-8" />
      <title>notes</title>

  </head>
  <body class='markdown-preview' data-use-github-style><h1 id="neural-style-transfer">Neural Style Transfer</h1>
<h1 id="what">What</h1>
<p>It can apply an image&#39;s style on another image.</p>
<h1 id="limitations-">Limitations:</h1>
<h2 id="processing-time">Processing time</h2>
<p>The style transfer needs to run a large amount of iterations on an image to get good result. The result isn&#39;t instant - expect ~40secs per image on a machine with latest commercial GPU. We could improve this by throwing more GPUs at it, of course.</p>
<h2 id="parameters">Parameters</h2>
<p>The output&#39;s look depend on content and style image, as well as a set of parameters that define how the process runs.</p>
<p>There isn&#39;t a set of parameters that work well for any combinations of content + style images, unfortunately. However, content images that look alike can reuse the same set and get good results.</p>
<h1 id="possible-uses-in-project">Possible uses in project</h1>
<ul>
<li><strong>Neural Style Photobooth</strong></li>
</ul>
<h1 id="tricks-discoveries">Tricks &amp; Discoveries</h1>
<ul>
<li><p><strong>Content and Style images that are similar in composition work better together.</strong>
The algorithm matches similar patches between two images and transfers styles accordingly. If both images have backdrop with minimal textures, and a foreground that has more things going on, it&#39;ll transfer the backdrop&#39;s style to backdrop and foreground to foreground.
<em>TODO</em> example</p>
</li>
<li><p><strong>Textures transfer better than contextual images as style</strong>
<em>TODO</em> examples</p>
</li>
<li><p><strong>With <code>normalize_gradients</code> on, avoid setting <code>tv_weight</code> too high</strong>.
Both try to smoothen the images, so both on would just melt it.
<em>TODO</em> examples</p>
</li>
<li><p>When style_weight / content_weight is kept the same, and normalized is turned off, changing the magnitude of two weights don&#39;t really affect output; However with normalized on these magnitudes affect how blended the final image is.
<img src="style_content_ratio_same.png" alt="example"></p>
</li>
</ul>
<h1 id="hypothesis-in-trial">Hypothesis in Trial</h1>
<p>Below are a few hypothesis in the progress of testing.</p>
<ul>
<li>Bigger <code>tv_weight</code> would make the noise patches bigger, giving the look of noise reduced.</li>
<li><code>learning_rate</code> affects the speed of learning, therefore affecting how much NN knows about the images.
-</li>
</ul></body>
</html>
